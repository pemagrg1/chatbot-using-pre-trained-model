{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfRZpZ8omt2wnBco5Vbufu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pemagrg1/chatbot-using-pre-trained-model/blob/main/MusicFestivalChatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c5ZAdCAmq8Qi",
        "outputId": "15b91bd3-f56e-41d0-ae00-af34a3d379e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GODEL'...\n",
            "remote: Enumerating objects: 282, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 282 (delta 62), reused 48 (delta 46), pack-reused 200\u001b[K\n",
            "Receiving objects: 100% (282/282), 51.03 MiB | 24.63 MiB/s, done.\n",
            "Resolving deltas: 100% (99/99), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/microsoft/GODEL.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/GODEL')\n",
        "!pwd"
      ],
      "metadata": {
        "id": "1XFTa5JGr54z",
        "outputId": "c2647911-f8b1-4745-8aed-5c291198a45c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GODEL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# setting up the env"
      ],
      "metadata": {
        "id": "7H7qEVmyr94h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "F-1ikY_0rzFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install absl-py==0.15.0 accelerate==0.6.1 datasets==2.0.0 filelock==3.4.2 jsonlines==3.0.0 numpy==1.22.3 python-dotenv==0.20.0 rouge_score==0.0.4 six==1.16.0 torch==1.11.0 tqdm==4.64.0 transformers==4.17.0 wandb==0.12.11 fire==0.4.0\n"
      ],
      "metadata": {
        "id": "Hwtv7TUFx3vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install flask==2.0.2 flask-Cors==3.0.10 chardet==3.0.4 nltk==3.4.1 beautifulsoup4==4.6.0 zstandard==0.18.0 flashtext==2.7 dotmap"
      ],
      "metadata": {
        "id": "mdx89qfe0K7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the Dataset\n",
        "Download the dataset that we created\n"
      ],
      "metadata": {
        "id": "0LHZqvl35KVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/pemagrg1/chatbot-using-pre-trained-model/blob/main/MusicFestData/train_music_feat.jsonl"
      ],
      "metadata": {
        "id": "LZ0A4wAS5Mij",
        "outputId": "b7a83dea-8f05-4d42-9740-9b4f369b2b88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-16 23:00:49--  https://github.com/pemagrg1/chatbot-using-pre-trained-model/blob/main/MusicFestData/train_music_feat.jsonl\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45715 (45K) [text/plain]\n",
            "Saving to: ‘train_music_feat.jsonl’\n",
            "\n",
            "\rtrain_music_feat.js   0%[                    ]       0  --.-KB/s               \rtrain_music_feat.js 100%[===================>]  44.64K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-07-16 23:00:49 (12.5 MB/s) - ‘train_music_feat.jsonl’ saved [45715/45715]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/pemagrg1/chatbot-using-pre-trained-model/blob/main/MusicFestData/test_music_feat.jsonl"
      ],
      "metadata": {
        "id": "aXweMydI5RRW",
        "outputId": "b1694ced-c65f-483b-ed61-20c3b5af7e5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-16 23:04:08--  https://github.com/pemagrg1/chatbot-using-pre-trained-model/blob/main/MusicFestData/test_music_feat.jsonl\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29787 (29K) [text/plain]\n",
            "Saving to: ‘test_music_feat.jsonl’\n",
            "\n",
            "\rtest_music_feat.jso   0%[                    ]       0  --.-KB/s               \rtest_music_feat.jso 100%[===================>]  29.09K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-07-16 23:04:08 (16.8 MB/s) - ‘test_music_feat.jsonl’ saved [29787/29787]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changes:\n",
        "In \"/content/GODEL/examples/dstc9/dstc9_dataset.py\", enter the data path in **train_path** (line #43), **validation_path**, and **test_path**"
      ],
      "metadata": {
        "id": "VsyYbuLo5dtl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YF_K_s0o6OgL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the pretrained model"
      ],
      "metadata": {
        "id": "kqhqwV4YsAwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git lfs install\n",
        "! git clone https://huggingface.co/microsoft/GODEL-v1_1-base-seq2seq\n"
      ],
      "metadata": {
        "id": "j0G3MmafsErO",
        "outputId": "d22d1b44-2bc7-461a-f085-fae9a547b420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'GODEL-v1_1-base-seq2seq'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Total 23 (delta 0), reused 0 (delta 0), pack-reused 23\u001b[K\n",
            "Unpacking objects: 100% (23/23), 607.93 KiB | 4.31 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINETUNING"
      ],
      "metadata": {
        "id": "yhMAUsVXsN54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changes:\n",
        "1. In \"/content/GODEL/GODEL/train.py\", change the path **metric_rouge** and **metric_bleu**(line #558)"
      ],
      "metadata": {
        "id": "65lHtqKOw0wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "from datetime import datetime\n",
        "start_time = datetime.now()\n",
        "print(\"STart TIme:\",start_time)\n",
        "\n",
        "\n",
        "! python /content/GODEL/GODEL/train.py --model_name_or_path /content/GODEL/GODEL-v1_1-base-seq2seq \\\n",
        "\t--dataset_name /content/GODEL/examples/dstc9/dstc9_dataset.py \\\n",
        "\t--output_dir /content/GODEL/test_output \\\n",
        "\t--per_device_train_batch_size=4 \\\n",
        "\t--per_device_eval_batch_size=4 \\\n",
        "\t--max_target_length 512 \\\n",
        "\t--max_length 512 \\\n",
        "\t--num_train_epochs 1 \\\n",
        "\t--save_steps 10000 \\\n",
        "\t--num_beams 5 \\\n",
        "\t--exp_name test1 --preprocessing_num_workers 24\n",
        "\n",
        "end_time = datetime.now()\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ],
      "metadata": {
        "id": "eWhTEGIJsPDR",
        "outputId": "c8f73bff-40db-4a3e-cabd-b336e9c029b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STart TIme: 2023-07-16 23:09:18.080541\n",
            "2023-07-16 23:09:21.910565: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-16 23:09:23.389182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "07/16/2023 23:09:24 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cpu\n",
            "Mixed precision type: no\n",
            "\n",
            "07/16/2023 23:09:24 - WARNING - datasets.builder - Using custom data configuration default\n",
            "07/16/2023 23:09:24 - WARNING - datasets.builder - Reusing dataset dstc9 (/root/.cache/huggingface/datasets/dstc9/default/0.0.0/8ab4e0b4e761131d474ba6d6a5214c6447bf75c64c26cd10c40151a584807049)\n",
            "100% 3/3 [00:00<00:00, 802.12it/s]\n",
            "loading configuration file /content/GODEL/GODEL-v1_1-base-seq2seq/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"/content/GODEL/GODEL-v1_1-base-seq2seq\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 3072,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32102\n",
            "}\n",
            "\n",
            "Didn't find file /content/GODEL/GODEL-v1_1-base-seq2seq/spiece.model. We won't load it.\n",
            "loading file None\n",
            "loading file /content/GODEL/GODEL-v1_1-base-seq2seq/tokenizer.json\n",
            "loading file /content/GODEL/GODEL-v1_1-base-seq2seq/added_tokens.json\n",
            "loading file /content/GODEL/GODEL-v1_1-base-seq2seq/special_tokens_map.json\n",
            "loading file /content/GODEL/GODEL-v1_1-base-seq2seq/tokenizer_config.json\n",
            "loading weights file /content/GODEL/GODEL-v1_1-base-seq2seq/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /content/GODEL/GODEL-v1_1-base-seq2seq.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "Assigning [PAD] to the pad_token key of the tokenizer\n",
            "07/16/2023 23:09:31 - WARNING - datasets.fingerprint - Parameter 'function'=<function main.<locals>.dataset_mapping_function at 0x7c690f304820> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "Processing dataset #0:   0% 0/1 [00:00<?, ?ba/s]\n",
            "Processing dataset #0: 100% 1/1 [00:00<00:00,  3.89ba/s]\n",
            "\n",
            "\n",
            "Processing dataset #2:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\n",
            "Processing dataset #1: 100% 1/1 [00:00<00:00,  4.06ba/s]\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #3:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Processing dataset #2: 100% 1/1 [00:00<00:00,  3.58ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #4:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Processing dataset #3: 100% 1/1 [00:00<00:00,  3.88ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #5:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #4: 100% 1/1 [00:00<00:00,  3.41ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #6:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #5: 100% 1/1 [00:00<00:00,  3.55ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #7:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #7: 100% 1/1 [00:00<00:00,  9.45ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #6: 100% 1/1 [00:00<00:00,  4.20ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #8:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #9:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #10:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #8: 100% 1/1 [00:00<00:00,  4.55ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #9: 100% 1/1 [00:00<00:00,  4.18ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #10: 100% 1/1 [00:00<00:00,  4.12ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #11:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #11: 100% 1/1 [00:00<00:00,  4.69ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #12:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #12: 100% 1/1 [00:00<00:00,  3.98ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #13:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #14:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #13: 100% 1/1 [00:00<00:00,  3.87ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #14: 100% 1/1 [00:00<00:00,  4.50ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #15:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #16:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #15: 100% 1/1 [00:00<00:00,  3.59ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #17:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #16: 100% 1/1 [00:00<00:00,  3.50ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #17: 100% 1/1 [00:00<00:00,  3.43ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #18:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #18: 100% 1/1 [00:00<00:00,  3.96ba/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing dataset #19: 100% 1/1 [00:00<00:00,  4.70ba/s]\n",
            "Processing dataset #20: 100% 1/1 [00:00<00:00,  7.25ba/s]\n",
            "Processing dataset #21: 100% 1/1 [00:00<00:00, 10.61ba/s]\n",
            "Processing dataset #22: 100% 1/1 [00:00<00:00, 16.42ba/s]\n",
            "Processing dataset #23: 100% 1/1 [00:00<00:00, 11.34ba/s]\n",
            "07/16/2023 23:09:39 - WARNING - datasets.arrow_dataset - num_proc must be <= 3. Reducing num_proc to 3 for dataset of size 3.\n",
            "Processing dataset #0:   0% 0/1 [00:00<?, ?ba/s]\n",
            "Processing dataset #0: 100% 1/1 [00:00<00:00, 14.71ba/s]\n",
            "\n",
            "\n",
            "Processing dataset #1: 100% 1/1 [00:00<00:00, 13.61ba/s]\n",
            "Processing dataset #2: 100% 1/1 [00:00<00:00, 13.79ba/s]\n",
            "07/16/2023 23:09:40 - WARNING - datasets.arrow_dataset - num_proc must be <= 3. Reducing num_proc to 3 for dataset of size 3.\n",
            "Processing dataset #0: 100% 1/1 [00:00<00:00, 13.73ba/s]\n",
            "\n",
            "Processing dataset #1:   0% 0/1 [00:00<?, ?ba/s]\u001b[A\n",
            "\n",
            "Processing dataset #1: 100% 1/1 [00:00<00:00, 16.41ba/s]\n",
            "Processing dataset #2: 100% 1/1 [00:00<00:00, 16.11ba/s]\n",
            "07/16/2023 23:09:41 - INFO - __main__ - Sample 30 of the training set: {'input_ids': [531, 25, 114, 723, 14856, 58, 32100, 2163, 6, 27, 103, 5, 290, 19, 3, 9, 418, 12, 114, 81, 723, 14856, 5, 32100, 1615, 103, 25, 114, 723, 14856, 58, 32100, 2070, 14856, 1086, 915, 3, 9, 1148, 1196, 13, 4183, 7357, 11, 92, 462, 3, 9, 207, 7235, 351, 11, 2779, 4643, 5, 32100, 531, 25, 214, 81, 8, 723, 3994, 16, 17807, 58, 32100, 8704, 17, 15337, 49, 12313, 3397, 11, 8, 180, 15472, 5550, 3397, 16, 17807, 5, 32100, 363, 31, 7, 8, 723, 2486, 13, 135, 58, 3, 2, 9175, 439, 7651, 13553, 9175, 3155, 1593, 10, 363, 31, 7, 8, 723, 2486, 58, 71, 10, 290, 56, 36, 3, 9, 2486, 13, 9948, 6, 2783, 6, 2480, 11, 7180, 2431, 7, 5, 3, 15425, 1, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102, 32102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [71, 418, 6, 132, 56, 36, 3, 9, 2486, 13, 9948, 6, 2783, 6, 2480, 11, 7180, 2431, 7, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "07/16/2023 23:09:41 - INFO - __main__ - ***** Running training *****\n",
            "07/16/2023 23:09:41 - INFO - __main__ -   Num examples = 35\n",
            "07/16/2023 23:09:41 - INFO - __main__ -   Num Epochs = 1\n",
            "07/16/2023 23:09:41 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
            "07/16/2023 23:09:41 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "07/16/2023 23:09:41 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "07/16/2023 23:09:41 - INFO - __main__ -   Total optimization steps = 9\n",
            "  0% 0/9 [00:00<?, ?it/s]^C\n",
            "Duration: 0:01:10.156699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tCt4zpIAxpEi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}